#!/bin/bash
#SBATCH --job-name=repack_pillar384
#SBATCH --nodes=1
##SBATCH --nodelist=node001
#SBATCH --cpus-per-task=64
#SBATCH --output=/home/ld258/ipredict/slurm_logs/oracle-ct/repack_pillar384-output-%j.out
#SBATCH --error=/home/ld258/ipredict/slurm_logs/oracle-ct/repack_pillar384-error-%j.out
#SBATCH --mem=900G

module load miniconda/py39_4.12.0

source "$(conda info --base)/etc/profile.d/conda.sh"
conda activate fvlm

# ==============================================================================
# CONFIGURATION
# ==============================================================================

NII_DIR="/scratch/railabs/ld258/dataset/merlin/merlinabdominalctdataset/merlin_data"
LABELS_CSV="/scratch/railabs/ld258/dataset/merlin/merlinabdominalctdataset/zero_shot_findings_disease_cls.csv"
NII_CSV="/scratch/railabs/ld258/dataset/merlin/nii_paths.csv"
OUTPUT_DIR="/cachedata/ld258/janus/merlin/pillar_packs_384"

ORACLE_CT_ROOT="/home/ld258/ipredict/oracle-ct/oracle_ct"

# ==============================================================================
# STEP 1: Generate nii_csv (case_id → nii_path mapping)
# ==============================================================================

echo "=== Step 1: Generating nii_paths.csv ==="
python ${ORACLE_CT_ROOT}/scripts/make_nii_csv.py \
    --nii_dir    ${NII_DIR} \
    --output     ${NII_CSV} \
    --labels_csv ${LABELS_CSV}

echo "nii_paths.csv saved to: ${NII_CSV}"

# ==============================================================================
# STEP 2: Repack NIfTI → 384³ 1.5mm RAVE LZ4 packs
# ==============================================================================

echo ""
echo "=== Step 2: Repacking to 384³ RAVE LZ4 ==="
python ${ORACLE_CT_ROOT}/scripts/repack_pillar384.py \
    --nii_csv    ${NII_CSV} \
    --output_dir ${OUTPUT_DIR} \
    --workers    48

echo ""
echo "=== Done. Packs saved to: ${OUTPUT_DIR} ==="
