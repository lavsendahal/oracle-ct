#!/bin/bash
#SBATCH --job-name=INFERENCE
#SBATCH --nodes=1
##SBATCH --nodelist=node001
#SBATCH --gres=gpu:a6000:4
#SBATCH --cpus-per-task=64
# NOTE: SBATCH directives don't expand env vars - use absolute paths or %x/%j only
#SBATCH --output=/home/ld258/ipredict/slurm_logs/INFER_output-%j.out
#SBATCH --error=/home/ld258/ipredict/slurm_logs/INFER_error-%j.out


# Default: use all available GPUs
NGPUS=${NGPUS:-$(nvidia-smi -L | wc -l)}

# Activate conda
module load miniconda/py39_4.12.0
source "$(conda info --base)/etc/profile.d/conda.sh"
conda activate fvlm
export PYTHONPATH=$IPREDICT_ROOT/neuro_symbolic/:$PYTHONPATH

export MASTER_ADDR=$(hostname -s)
export MASTER_PORT=$((10000 + RANDOM % 50000))


export HF_TOKEN=$HUGGINGFACE_HUB_TOKEN

export HF_HOME=$SCRATCH/hf_home
export HF_HUB_CACHE=$HF_HOME/hub

# Optimize CPU threading for multi-GPU + DataLoader workers
# Formula: total_cores / (num_gpus * (1 + num_workers))
# 128 cores / (8 GPUs * (1 main + 4 workers)) = 128/40 â‰ˆ 3
export OMP_NUM_THREADS=3
export MKL_NUM_THREADS=3  # For Intel MKL (if used)

echo "CPU Threading Configuration:"
echo "  OMP_NUM_THREADS: $OMP_NUM_THREADS"
echo "  MKL_NUM_THREADS: $MKL_NUM_THREADS"



echo "========================================"
echo "RadioPrior v2 - Multi-GPU INFERENCE"
echo "========================================"
echo "Number of GPUs: $NGPUS"
echo "Arguments: $@"
echo "========================================"
echo ""

# Launch with torchrun (recommended for PyTorch >= 1.10)
torchrun \
    --standalone \
    --nnodes=1 \
    --nproc_per_node=$NGPUS \
    $IPREDICT_ROOT/neuro_symbolic/janus/inference.py \
    experiment=dinov3_gated_fusion \
    paths.checkpoint=$IPREDICT_ROOT/neuro_symbolic/outputs/RadioPriorGatedFusion/2026-01-20_07-02-23_seed25/checkpoints/radiopriorgatedfusion_best_macro_auc0.8832.pt \
    logging.use_wandb=false \
    training.use_ddp=true \
    "$@"

