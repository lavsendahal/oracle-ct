#!/bin/bash
#SBATCH --job-name=INFERENCE
#SBATCH --nodes=1
##SBATCH --nodelist=node001
#SBATCH --gres=gpu:a6000:6
#SBATCH --cpus-per-task=80
# NOTE: SBATCH directives don't expand env vars - use absolute paths or %x/%j only
#SBATCH --output=/home/ld258/ipredict/slurm_logs/miccai_janus/INFER_merlin-output-%j.out
#SBATCH --error=/home/ld258/ipredict/slurm_logs/miccai_janus/INFER_merlin-error-%j.out


# Default: use all available GPUs
NGPUS=${NGPUS:-$(nvidia-smi -L | wc -l)}

# Activate conda
module load miniconda/py39_4.12.0
source "$(conda info --base)/etc/profile.d/conda.sh"
conda activate fvlm
export PYTHONPATH=$IPREDICT_ROOT/neuro_symbolic/:$PYTHONPATH

export MASTER_ADDR=$(hostname -s)
export MASTER_PORT=$((10000 + RANDOM % 50000))


export HF_TOKEN=$HUGGINGFACE_HUB_TOKEN

export HF_HOME=$SCRATCH/hf_home
export HF_HUB_CACHE=$HF_HOME/hub

# Optimize CPU threading for multi-GPU + DataLoader workers
# Formula: total_cores / (num_gpus * (1 + num_workers))
# 128 cores / (8 GPUs * (1 main + 4 workers)) = 128/40 â‰ˆ 3
export OMP_NUM_THREADS=3
export MKL_NUM_THREADS=3  # For Intel MKL (if used)

echo "CPU Threading Configuration:"
echo "  OMP_NUM_THREADS: $OMP_NUM_THREADS"
echo "  MKL_NUM_THREADS: $MKL_NUM_THREADS"



echo "========================================"
echo "Janus - Multi-GPU INFERENCE"
echo "========================================"
echo "Number of GPUs: $NGPUS"
echo "Arguments: $@"
echo "========================================"
echo ""

# Configuration - SET THESE BEFORE RUNNING or pass as environment variables
# Example: DATASET=duke EXPERIMENT=dinov3_gated_fusion sbatch slurm_inference.sub
DATASET=${DATASET:-merlin}           # merlin or duke
EXPERIMENT=${EXPERIMENT:-dinov3_baseline_gap}
CHECKPOINT=${CHECKPOINT:-/scratch/railabs/ld258/output/ct_triage/janus/runs/JanusGAP/2026-02-10_16-42-53_seed25/checkpoints/gap_best_macro_auc0.8488.pt}

echo "Dataset: $DATASET"
echo "Experiment: $EXPERIMENT"
echo "Checkpoint: $CHECKPOINT"
echo ""

# Launch with torchrun (recommended for PyTorch >= 1.10)
torchrun \
    --standalone \
    --nnodes=1 \
    --nproc_per_node=$NGPUS \
    /home/ld258/ipredict/janus/inference.py \
    dataset=$DATASET \
    experiment=$EXPERIMENT \
    paths.checkpoint=$CHECKPOINT \
    +inference.return_ungated=true \
    logging.use_wandb=false \
    training.use_ddp=true \
    "$@"




# # Launch with torchrun (recommended for PyTorch >= 1.10)
# torchrun \
#     --standalone \
#     --nnodes=1 \
#     --nproc_per_node=$NGPUS \
#     /home/ld258/ipredict/janus/inference.py \
#     dataset=$DATASET \
#     experiment=$EXPERIMENT \
#     paths.checkpoint=$CHECKPOINT \
#     +inference.split=val \
#     +inference.return_ungated=true \
#     logging.use_wandb=false \
#     training.use_ddp=true \
#     "$@"



