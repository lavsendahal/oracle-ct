# @package _global_

# Pillar-0 + Global Average Pooling (Option B baseline)
#
# Uses pretrained Pillar-0 AbdomenCT backbone with all 11 HU windows intact.
# Input: [B, 11, 384, 384, 384] from PillarDataset
# Features: pooled [B, 1152] → per-disease Linear(1152, 1)
#
# Train from pillar-pretrain/oracle-ct/:
#   torchrun --nproc_per_node=4 train.py \
#     experiment=pillar_gap \
#     dataset=merlin_pillar \
#     model.model_repo_id=/path/to/local/pillar_model

model:
  name: OracleCT_Pillar_GAP
  num_diseases: 30
  disease_names: null               # null = use first 30 from ALL_DISEASES
  model_repo_id: "YalaLab/Pillar0-AbdomenCT"  # HuggingFace repo or local path
  model_revision: null              # null = latest; set to specific revision/tag
  freeze_backbone: false            # fine-tune backbone end-to-end
  modality: abdomen_ct

training:
  max_epochs: 20
  learning_rate: 1e-4               # lower LR for large pretrained backbone
  warmup_epochs: 2
  use_group_lrs: true
  head_lr_scale: 5.0                # heads learn faster than backbone
  alpha_lr_scale: 0.3
  gradient_accumulation_steps: 4   # effective batch = 4 × N_gpus × accum
  use_amp: true

logging:
  use_wandb: false
